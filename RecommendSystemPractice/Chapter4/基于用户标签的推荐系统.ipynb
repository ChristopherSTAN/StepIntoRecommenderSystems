{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于用户标签的推荐\n",
    "标签系统的最大优势在于可以发挥群体智能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入包\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一. 通用函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义装饰器，监控运行时间\n",
    "def timmer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        res = func(*args, **kwargs)\n",
    "        stop_time = time.time()\n",
    "        print('Func %s, run time: %s' % (func.__name__, stop_time - start_time))\n",
    "        return res\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据处理相关\n",
    "Delicious-2k数据集\n",
    "1. load data\n",
    "2. split data\n",
    "\n",
    "原书中用到了两个数据集Delicious,CiteULike，注意各自的数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    \n",
    "    def __init__(self, fp):\n",
    "        # fp: data file path\n",
    "        self.data = self.loadData(fp)\n",
    "    \n",
    "    @timmer\n",
    "    def loadData(self, fp):\n",
    "        data = [f.strip().split('\\t')[:3] for f in open(fp).readlines()[1:]]\n",
    "        new_data = {}\n",
    "        for user, item, tag in data:\n",
    "            if user not in new_data:\n",
    "                new_data[user] = {}\n",
    "            if item not in new_data[user]:\n",
    "                new_data[user][item] = set()\n",
    "            new_data[user][item].add(tag)\n",
    "        ret = []\n",
    "        for user in new_data:\n",
    "            for item in new_data[user]:\n",
    "                #整合同一个用户对同一个物品的多个tag，方便后面按(user,item)划分\n",
    "                ret.append((user, item, list(new_data[user][item])))\n",
    "        return ret\n",
    "    \n",
    "    @timmer\n",
    "    def splitData(self, M, k, seed=1):\n",
    "        '''\n",
    "        :params: data, 加载的所有(user, item)数据条目\n",
    "        :params: M, 划分的数目，最后需要取M折的平均\n",
    "        :params: k, 本次是第几次划分，k~[0, M)\n",
    "        :params: seed, random的种子数，对于不同的k应设置成一样的\n",
    "        :return: train, test\n",
    "        '''\n",
    "        # 按照(user, item)作为key进行划分\n",
    "        train, test = [], []\n",
    "        random.seed(seed)\n",
    "        for user, item, tags in self.data:\n",
    "            # 这里与书中的不一致，本人认为取M-1较为合理，因randint是左右都覆盖的\n",
    "            if random.randint(0, M-1) == k:  \n",
    "                test.append((user, item, tags))\n",
    "            else:\n",
    "                train.append((user, item, tags))\n",
    "\n",
    "        # 处理成字典的形式，user->set(items)\n",
    "        def convert_dict(data):\n",
    "            data_dict = {}\n",
    "            for user, item, tags in data:\n",
    "                if user not in data_dict:\n",
    "                    data_dict[user] = {}\n",
    "                data_dict[user][item] = tags\n",
    "            return data_dict\n",
    "\n",
    "        return convert_dict(train), convert_dict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 评价指标\n",
    "1. Precision\n",
    "2. Recall\n",
    "3. Coverage\n",
    "4. Diversity\n",
    "5. Popularity(Novelty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric():\n",
    "    def __init__(self, train, test, GetRecommendation):\n",
    "        '''\n",
    "        :params: train, 训练数据\n",
    "        :params: test, 测试数据\n",
    "        :params: GetRecommendation, 为某个用户获取推荐物品的接口函数\n",
    "        '''\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.GetRecommendation = GetRecommendation\n",
    "        self.recs = self.getRec()\n",
    "\n",
    "    # 为test中的每个用户进行推荐\n",
    "    def getRec(self):\n",
    "        recs = {}\n",
    "        for user in self.test:\n",
    "            rank = self.GetRecommendation(user)\n",
    "            recs[user] = rank\n",
    "        return recs\n",
    "\n",
    "    # 定义精确率指标计算方式\n",
    "    def precision(self):\n",
    "        all, hit = 0, 0\n",
    "        for user in self.test:\n",
    "            test_items = set(self.test[user])\n",
    "            rank = self.recs[user]\n",
    "            for item, score in rank:\n",
    "                if item in test_items:\n",
    "                    hit += 1\n",
    "            all += len(rank)\n",
    "        return round(hit / all * 100, 2)\n",
    "\n",
    "    # 定义召回率指标计算方式\n",
    "    def recall(self):\n",
    "        all, hit = 0, 0\n",
    "        for user in self.test:\n",
    "            test_items = set(self.test[user])\n",
    "            rank = self.recs[user]\n",
    "            for item, score in rank:\n",
    "                if item in test_items:\n",
    "                    hit += 1\n",
    "            all += len(test_items)\n",
    "        return round(hit / all * 100, 2)\n",
    "\n",
    "    # 定义覆盖率指标计算方式\n",
    "    def coverage(self):\n",
    "        all_item, recom_item = set(), set()\n",
    "        for user in self.train:\n",
    "            for item in self.train[user]:\n",
    "                all_item.add(item)\n",
    "        for user in self.test:\n",
    "            rank = self.recs[user]\n",
    "            for item, score in rank:\n",
    "                recom_item.add(item)\n",
    "        return round(len(recom_item) / len(all_item) * 100, 2)\n",
    "\n",
    "    # 定义多样性指标计算方式\n",
    "    def diversity(self):\n",
    "        # item_tags[i]表示物品i的标签向量，item_tags[i][b]表示对物品i打标签b的次数，即物品i的标签向量在标签b上的分量\n",
    "        item_tags = {}\n",
    "        for user in self.train:\n",
    "            for item in self.train[user]:\n",
    "                if item not in item_tags:\n",
    "                    item_tags[item] = {}\n",
    "                for tag in self.train[user][item]:\n",
    "                    if tag not in item_tags[item]:\n",
    "                        item_tags[item][tag] = 0\n",
    "                    item_tags[item][tag] += 1  #对item打标签tag的次数\n",
    "\n",
    "        # 计算两个item的相似度\n",
    "        def CosineSim(u, v):\n",
    "            ret = 0\n",
    "            for tag in item_tags[u]:\n",
    "                if tag in item_tags[v]:\n",
    "                    ret += item_tags[u][tag] * item_tags[v][tag]  #点积\n",
    "            nu, nv = 0, 0\n",
    "            for tag in item_tags[u]:\n",
    "                nu += item_tags[u][tag]**2\n",
    "            for tag in item_tags[v]:\n",
    "                nv += item_tags[v][tag]**2\n",
    "            return ret / math.sqrt(nu * nv)  #物品u,v的标签向量的余弦相似度\n",
    "\n",
    "        # 计算Diversity，改进一下：div没必要保留每个用户的多样性，直接累计\n",
    "        #div = []\n",
    "        div = 0\n",
    "        for user in self.test:\n",
    "            rank = self.recs[user]\n",
    "            sim, cnt = 0, 0\n",
    "            for u, _ in rank:\n",
    "                for v, _ in rank:\n",
    "                    if u == v:\n",
    "                        continue\n",
    "                    sim += CosineSim(u, v)  #累计推荐列表中物品间的相似性\n",
    "                    cnt += 1  #推荐列表中物品两两组合数，当然也可以不用累计直接写出来\n",
    "            sim = sim / cnt if sim != 0 else 0\n",
    "            #div.append(1 - sim)     #1-sim是单个用户的推荐列表的多样性\n",
    "            div += 1 - sim\n",
    "        #return sum(div) / len(div)  #推荐系统的多样性为所有用户推荐列表多样性的平均值\n",
    "        return div / len(self.test)\n",
    "\n",
    "    # 定义新颖度指标计算方式:其实用的是流行度，流行度越高，新颖度越低\n",
    "    def popularity(self):\n",
    "        # 计算物品的流行度，为给这个物品打过标签的用户数\n",
    "        item_pop = {}\n",
    "        for user in self.train:\n",
    "            for item in self.train[user]:\n",
    "                if item not in item_pop:\n",
    "                    item_pop[item] = 0\n",
    "                item_pop[item] += 1\n",
    "\n",
    "        num, pop = 0, 0\n",
    "        for user in self.test:\n",
    "            rank = self.recs[user]\n",
    "            for item, score in rank:\n",
    "                # 取对数，防止因长尾问题带来的被流行物品所主导\n",
    "                pop += math.log(1 + item_pop[item])\n",
    "                num += 1\n",
    "        return round(pop / num, 6)\n",
    "\n",
    "    def eval(self):\n",
    "        metric = {\n",
    "            'Precision': self.precision(),\n",
    "            'Recall': self.recall(),\n",
    "            'Coverage': self.coverage(),\n",
    "            'Diversity': self.diversity(),\n",
    "            'Popularity': self.popularity()\n",
    "        }\n",
    "        print('Metric:', metric)\n",
    "        return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二. 算法实现\n",
    "1. SimpleTagBased\n",
    "2. TagBasedTFIDF\n",
    "3. TagBasedTFIDF++\n",
    "4. TagExtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 基于热门标签的推荐： 对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给他\n",
    "def SimpleTagBased(train, N):\n",
    "    '''\n",
    "    :params: train, 训练数据集\n",
    "    :params: N, 超参数，设置取TopN推荐物品数目\n",
    "    :return: GetRecommendation，推荐接口函数\n",
    "    '''\n",
    "    # 统计user_tags和tag_items\n",
    "    user_tags, tag_items = {}, {}\n",
    "    for user in train:\n",
    "        user_tags[user] = {}\n",
    "        for item in train[user]:\n",
    "            for tag in train[user][item]:\n",
    "                if tag not in user_tags[user]:\n",
    "                    user_tags[user][tag] = 0\n",
    "                user_tags[user][tag] += 1  #user打了多少次tag\n",
    "                if tag not in tag_items:\n",
    "                    tag_items[tag] = {}\n",
    "                if item not in tag_items[tag]:\n",
    "                    tag_items[tag][item] = 0\n",
    "                tag_items[tag][item] += 1  #item被打了多少次tag\n",
    "\n",
    "    def GetRecommendation(user):\n",
    "        # 按照打分推荐N个未见过的\n",
    "        if user not in user_tags:\n",
    "            return []\n",
    "        seen_items = set(train[user])\n",
    "        item_score = {}\n",
    "        for tag in user_tags[user]:\n",
    "            for item in tag_items[tag]:\n",
    "                if item in seen_items:\n",
    "                    continue\n",
    "                if item not in item_score:\n",
    "                    item_score[item] = 0\n",
    "                    #通过user-tag与tag-item之间的关系来建立user-item的关系\n",
    "                item_score[item] += user_tags[user][tag] * tag_items[tag][item]\n",
    "        item_score = list(\n",
    "            sorted(item_score.items(), key=lambda x: x[1], reverse=True))\n",
    "        return item_score[:N]\n",
    "\n",
    "    return GetRecommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 改进一：为热门标签加入惩罚项，性能全面提升\n",
    "def TagBasedTFIDF(train, N):\n",
    "    '''\n",
    "    :params: train, 训练数据集\n",
    "    :params: N, 超参数，设置取TopN推荐物品数目\n",
    "    :return: GetRecommendation，推荐接口函数\n",
    "    '''\n",
    "    # 统计user_tags和tag_items\n",
    "    user_tags, tag_items = {}, {}\n",
    "    # 统计标签的热门程度，即打过此标签的不同用户数\n",
    "    tag_pop = {}\n",
    "    for user in train:\n",
    "        user_tags[user] = {}\n",
    "        for item in train[user]:\n",
    "            for tag in train[user][item]:\n",
    "                if tag not in user_tags[user]:\n",
    "                    user_tags[user][tag] = 0\n",
    "                user_tags[user][tag] += 1\n",
    "                if tag not in tag_items:\n",
    "                    tag_items[tag] = {}\n",
    "                if item not in tag_items[tag]:\n",
    "                    tag_items[tag][item] = 0\n",
    "                tag_items[tag][item] += 1\n",
    "                if tag not in tag_pop:\n",
    "                    tag_pop[tag] = set() #取集合，避免重复\n",
    "                tag_pop[tag].add(user)\n",
    "    tag_pop = {k: len(v) for k, v in tag_pop.items()} #标签的热门程度\n",
    "    \n",
    "    def GetRecommendation(user):\n",
    "        # 按照打分推荐N个未见过的\n",
    "        if user not in user_tags:\n",
    "            return []\n",
    "        seen_items = set(train[user])\n",
    "        item_score = {}\n",
    "        for tag in user_tags[user]:\n",
    "            for item in tag_items[tag]:\n",
    "                if item in seen_items:\n",
    "                    continue\n",
    "                if item not in item_score:\n",
    "                    item_score[item] = 0\n",
    "                #按tag_popularity进行惩罚\n",
    "                item_score[item] += user_tags[user][tag] * tag_items[tag][item] / tag_pop[tag]\n",
    "        item_score = list(sorted(item_score.items(), key=lambda x: x[1], reverse=True))\n",
    "        return item_score[:N]\n",
    "    \n",
    "    return GetRecommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 改进二：同时惩罚热门标签和热门物品\n",
    "def TagBasedTFIDF_Improved(train, N):\n",
    "    '''\n",
    "    :params: train, 训练数据集\n",
    "    :params: N, 超参数，设置取TopN推荐物品数目\n",
    "    :return: GetRecommendation，推荐接口函数\n",
    "    '''\n",
    "    # 统计user_tags和tag_items\n",
    "    user_tags, tag_items = {}, {}\n",
    "    # 统计标签和物品的热门程度，即打过此标签的不同用户数，和物品对应的不同用户数\n",
    "    tag_pop, item_pop = {}, {}\n",
    "    for user in train:\n",
    "        user_tags[user] = {}\n",
    "        for item in train[user]:\n",
    "            if item not in item_pop:\n",
    "                item_pop[item] = 0\n",
    "            item_pop[item] += 1\n",
    "            for tag in train[user][item]:\n",
    "                if tag not in user_tags[user]:\n",
    "                    user_tags[user][tag] = 0\n",
    "                user_tags[user][tag] += 1\n",
    "                if tag not in tag_items:\n",
    "                    tag_items[tag] = {}\n",
    "                if item not in tag_items[tag]:\n",
    "                    tag_items[tag][item] = 0\n",
    "                tag_items[tag][item] += 1\n",
    "                if tag not in tag_pop:\n",
    "                    tag_pop[tag] = set()\n",
    "                tag_pop[tag].add(user)\n",
    "    tag_pop = {k: len(v) for k, v in tag_pop.items()}\n",
    "    \n",
    "    def GetRecommendation(user):\n",
    "        # 按照打分推荐N个未见过的\n",
    "        if user not in user_tags:\n",
    "            return []\n",
    "        seen_items = set(train[user])\n",
    "        item_score = {}\n",
    "        for tag in user_tags[user]:\n",
    "            for item in tag_items[tag]:\n",
    "                if item in seen_items:\n",
    "                    continue\n",
    "                if item not in item_score:\n",
    "                    item_score[item] = 0\n",
    "                #同时添加tag_pop和item_pop惩罚项\n",
    "                item_score[item] += user_tags[user][tag] * tag_items[tag][item] / tag_pop[tag] / item_pop[item]\n",
    "        item_score = list(sorted(item_score.items(), key=lambda x: x[1], reverse=True))\n",
    "        return item_score[:N]\n",
    "    \n",
    "    return GetRecommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 基于标签扩展的推荐：对于新用户或者新物品，用户u的标签列表B(u)与物品i的标签列表B(i)的交集中的标签很少,为了提高推荐的准确性\n",
    "# 可能需要对标签集合做扩展，加入一些和已有标签相似的标签（详见书P108)\n",
    "#统一用户的标签为自己最常用的M个标签(多的截断，少的扩展),然后按照SimpleTagBased即可\n",
    "def ExpandTagBased(train, N, M=20):\n",
    "    '''\n",
    "    :params: train, 训练数据集\n",
    "    :params: N, 超参数，设置取TopN推荐物品数目\n",
    "    :params: M，超参数，设置取TopM的标签填补不满M个标签的用户\n",
    "    :return: GetRecommendation，推荐接口函数\n",
    "    '''\n",
    "    \n",
    "    # 1. 计算标签之间的相似度\n",
    "    item_tag = {}\n",
    "    for user in train:\n",
    "        for item in train[user]:\n",
    "            if item not in item_tag:\n",
    "                item_tag[item] = set()\n",
    "            for tag in train[user][item]:\n",
    "                item_tag[item].add(tag)\n",
    "    tag_sim, tag_cnt = {}, {}\n",
    "    for item in item_tag:\n",
    "        for u in item_tag[item]:\n",
    "            if u not in tag_cnt:\n",
    "                tag_cnt[u] = 0\n",
    "            tag_cnt[u] += 1\n",
    "            if u not in tag_sim:\n",
    "                tag_sim[u] = {}\n",
    "            for v in item_tag[item]:\n",
    "                if u == v:\n",
    "                    continue\n",
    "                if v not in tag_sim[u]:\n",
    "                    tag_sim[u][v] = 0\n",
    "                tag_sim[u][v] += 1 #标签u,v共现的次数\n",
    "    for u in tag_sim:\n",
    "        for v in tag_sim[u]:\n",
    "            #按标签被使用次数进行惩罚\n",
    "            tag_sim[u][v] /= math.sqrt(tag_cnt[u] * tag_cnt[v])\n",
    "    \n",
    "    # 2. 为每个用户扩展标签\n",
    "    user_tags = {}\n",
    "    for user in train:\n",
    "        if user not in user_tags:\n",
    "            user_tags[user] = {}\n",
    "        for item in train[user]:\n",
    "            for tag in train[user][item]:\n",
    "                if tag not in user_tags[user]:\n",
    "                    user_tags[user][tag] = 0\n",
    "                user_tags[user][tag] += 1\n",
    "    expand_tags = {}\n",
    "    for user in user_tags:\n",
    "        if len(user_tags[user]) >= M:\n",
    "            expand_tags[user] = user_tags[user]\n",
    "            continue\n",
    "        # 不满M个的进行标签扩展\n",
    "        expand_tags[user] = {}\n",
    "        seen_tags = set(user_tags[user])\n",
    "        for tag in user_tags[user]:\n",
    "            for t in tag_sim[tag]:\n",
    "                if t in seen_tags:\n",
    "                    continue\n",
    "                if t not in expand_tags[user]:\n",
    "                    expand_tags[user][t] = 0\n",
    "                #user_tags[user][tag]表示user打了多少次tag, tag_sim[tag][t]表示扩展标签t和tag的相似性\n",
    "                #二者乘积表示预计user会打多少次扩展标签t\n",
    "                expand_tags[user][t] += user_tags[user][tag] * tag_sim[tag][t]\n",
    "        expand_tags[user].update(user_tags[user]) #update: 将参数字典并入原字典\n",
    "        expand_tags[user] = dict(list(sorted(expand_tags[user].items(), key=lambda x: x[1], reverse=True))[:M])\n",
    "        \n",
    "    # 3. SimpleTagBased算法\n",
    "    tag_items = {}\n",
    "    for user in train:\n",
    "        for item in train[user]:\n",
    "            for tag in train[user][item]:\n",
    "                if tag not in tag_items:\n",
    "                    tag_items[tag] = {}\n",
    "                if item not in tag_items[tag]:\n",
    "                    tag_items[tag][item] = 0\n",
    "                tag_items[tag][item] += 1\n",
    "    \n",
    "    def GetRecommendation(user):\n",
    "        # 按照打分推荐N个未见过的\n",
    "        if user not in user_tags:\n",
    "            return []\n",
    "        seen_items = set(train[user])\n",
    "        item_score = {}\n",
    "        for tag in expand_tags[user]:\n",
    "            for item in tag_items[tag]:\n",
    "                if item in seen_items:\n",
    "                    continue\n",
    "                if item not in item_score:\n",
    "                    item_score[item] = 0\n",
    "                item_score[item] += expand_tags[user][tag] * tag_items[tag][item]\n",
    "        item_score = list(sorted(item_score.items(), key=lambda x: x[1], reverse=True))\n",
    "        return item_score[:N]\n",
    "    \n",
    "    return GetRecommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三. 实验\n",
    "1. SimpleTagBased实验\n",
    "2. TagBasedTFIDF实验\n",
    "3. TagBasedTFIDF++实验\n",
    "4. TagExtend\n",
    "\n",
    "M=10, N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment():\n",
    "    \n",
    "    def __init__(self, M, N, fp='../dataset/hetrec2011-delicious-2k/user_taggedbookmarks.dat', rt='SimpleTagBased'):\n",
    "        '''\n",
    "        :params: M, 进行多少次实验\n",
    "        :params: N, TopN推荐物品的个数\n",
    "        :params: fp, 数据文件路径\n",
    "        :params: rt, 推荐算法类型\n",
    "        '''\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        self.fp = fp\n",
    "        self.rt = rt\n",
    "        self.alg = {'SimpleTagBased': SimpleTagBased, 'TagBasedTFIDF': TagBasedTFIDF, \\\n",
    "                    'TagBasedTFIDF_Improved': TagBasedTFIDF_Improved, 'ExtendTagBased': ExpandTagBased}\n",
    "    \n",
    "    # 定义单次实验\n",
    "    @timmer\n",
    "    def worker(self, train, test):\n",
    "        '''\n",
    "        :params: train, 训练数据集\n",
    "        :params: test, 测试数据集\n",
    "        :return: 各指标的值\n",
    "        '''\n",
    "        getRecommendation = self.alg[self.rt](train, self.N)\n",
    "        metric = Metric(train, test, getRecommendation)\n",
    "        return metric.eval()\n",
    "    \n",
    "    # 多次实验取平均\n",
    "    @timmer\n",
    "    def run(self):\n",
    "        metrics = {'Precision': 0, 'Recall': 0, \n",
    "                   'Coverage': 0, 'Diversity': 0, \n",
    "                   'Popularity': 0}\n",
    "        dataset = Dataset(self.fp)\n",
    "        for ii in range(self.M):\n",
    "            train, test = dataset.splitData(self.M, ii)\n",
    "            print('Experiment {}:'.format(ii))\n",
    "            metric = self.worker(train, test)\n",
    "            metrics = {k: metrics[k]+metric[k] for k in metrics}\n",
    "        metrics = {k: metrics[k] / self.M for k in metrics}\n",
    "        print('Average Result (M={}, N={}): {}'.format(\\\n",
    "                              self.M, self.N, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func loadData, run time: 0.8748588562011719\n",
      "Func splitData, run time: 0.12141013145446777\n",
      "Experiment 0:\n",
      "Metric: {'Precision': 0.33, 'Recall': 0.54, 'Coverage': 3.32, 'Diversity': 0.7891727530611761, 'Popularity': 2.341877}\n",
      "Func worker, run time: 22.816081762313843\n",
      "Func splitData, run time: 0.1993856430053711\n",
      "Experiment 1:\n",
      "Metric: {'Precision': 0.36, 'Recall': 0.59, 'Coverage': 3.38, 'Diversity': 0.7892016733522945, 'Popularity': 2.32732}\n",
      "Func worker, run time: 23.225532054901123\n",
      "Func splitData, run time: 0.17270112037658691\n",
      "Experiment 2:\n",
      "Metric: {'Precision': 0.36, 'Recall': 0.59, 'Coverage': 3.36, 'Diversity': 0.7931677992034599, 'Popularity': 2.328602}\n",
      "Func worker, run time: 22.26242232322693\n",
      "Func splitData, run time: 0.1698317527770996\n",
      "Experiment 3:\n",
      "Metric: {'Precision': 0.29, 'Recall': 0.48, 'Coverage': 3.34, 'Diversity': 0.7981312775112238, 'Popularity': 2.365502}\n",
      "Func worker, run time: 22.684072971343994\n",
      "Func splitData, run time: 0.1663358211517334\n",
      "Experiment 4:\n",
      "Metric: {'Precision': 0.34, 'Recall': 0.56, 'Coverage': 3.32, 'Diversity': 0.7913632469975805, 'Popularity': 2.336359}\n",
      "Func worker, run time: 22.48362445831299\n",
      "Func splitData, run time: 0.17387723922729492\n",
      "Experiment 5:\n",
      "Metric: {'Precision': 0.34, 'Recall': 0.56, 'Coverage': 3.28, 'Diversity': 0.7898833759916356, 'Popularity': 2.346777}\n",
      "Func worker, run time: 22.609019994735718\n",
      "Func splitData, run time: 0.16887521743774414\n",
      "Experiment 6:\n",
      "Metric: {'Precision': 0.35, 'Recall': 0.56, 'Coverage': 3.48, 'Diversity': 0.7947883485550284, 'Popularity': 2.305997}\n",
      "Func worker, run time: 22.536576986312866\n",
      "Func splitData, run time: 0.17565011978149414\n",
      "Experiment 7:\n",
      "Metric: {'Precision': 0.33, 'Recall': 0.55, 'Coverage': 3.39, 'Diversity': 0.7909452548642726, 'Popularity': 2.363202}\n",
      "Func worker, run time: 23.52792763710022\n",
      "Func splitData, run time: 0.1664748191833496\n",
      "Experiment 8:\n",
      "Metric: {'Precision': 0.34, 'Recall': 0.55, 'Coverage': 3.37, 'Diversity': 0.7896235453026931, 'Popularity': 2.343951}\n",
      "Func worker, run time: 22.897080659866333\n",
      "Func splitData, run time: 0.22421741485595703\n",
      "Experiment 9:\n",
      "Metric: {'Precision': 0.35, 'Recall': 0.57, 'Coverage': 3.32, 'Diversity': 0.7882771564967721, 'Popularity': 2.341101}\n",
      "Func worker, run time: 22.291919469833374\n",
      "Average Result (M=10, N=10): {'Precision': 0.339, 'Recall': 0.5549999999999999, 'Coverage': 3.3560000000000003, 'Diversity': 0.7914554431336136, 'Popularity': 2.3400688}\n",
      "Func run, run time: 229.99353885650635\n"
     ]
    }
   ],
   "source": [
    "# 1. SimpleTagBased实验\n",
    "M, N = 10, 10\n",
    "exp = Experiment(M, N, rt='SimpleTagBased')\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func loadData, run time: 0.71378493309021\n",
      "Func splitData, run time: 0.16420221328735352\n",
      "Experiment 0:\n",
      "Metric: {'Precision': 0.38, 'Recall': 0.62, 'Coverage': 16.84, 'Diversity': 0.8817900402269333, 'Popularity': 1.324134}\n",
      "Func worker, run time: 26.290910243988037\n",
      "Func splitData, run time: 0.1636044979095459\n",
      "Experiment 1:\n",
      "Metric: {'Precision': 0.39, 'Recall': 0.64, 'Coverage': 16.95, 'Diversity': 0.8826879986677112, 'Popularity': 1.31696}\n",
      "Func worker, run time: 26.823615074157715\n",
      "Func splitData, run time: 0.16283702850341797\n",
      "Experiment 2:\n",
      "Metric: {'Precision': 0.35, 'Recall': 0.58, 'Coverage': 16.95, 'Diversity': 0.8810484811513308, 'Popularity': 1.32846}\n",
      "Func worker, run time: 26.88642692565918\n",
      "Func splitData, run time: 0.16982126235961914\n",
      "Experiment 3:\n",
      "Metric: {'Precision': 0.3, 'Recall': 0.5, 'Coverage': 16.98, 'Diversity': 0.8852801577135256, 'Popularity': 1.324036}\n",
      "Func worker, run time: 26.75504493713379\n",
      "Func splitData, run time: 0.19398927688598633\n",
      "Experiment 4:\n",
      "Metric: {'Precision': 0.39, 'Recall': 0.65, 'Coverage': 16.93, 'Diversity': 0.8839971850323287, 'Popularity': 1.318871}\n",
      "Func worker, run time: 26.96007204055786\n",
      "Func splitData, run time: 0.1655871868133545\n",
      "Experiment 5:\n",
      "Metric: {'Precision': 0.36, 'Recall': 0.59, 'Coverage': 16.86, 'Diversity': 0.8821039480380471, 'Popularity': 1.332353}\n",
      "Func worker, run time: 27.5167818069458\n",
      "Func splitData, run time: 0.16446232795715332\n",
      "Experiment 6:\n",
      "Metric: {'Precision': 0.36, 'Recall': 0.58, 'Coverage': 17.06, 'Diversity': 0.8857492798212573, 'Popularity': 1.317009}\n",
      "Func worker, run time: 25.140998601913452\n",
      "Func splitData, run time: 0.16391825675964355\n",
      "Experiment 7:\n",
      "Metric: {'Precision': 0.35, 'Recall': 0.58, 'Coverage': 17.08, 'Diversity': 0.8822245571373106, 'Popularity': 1.331852}\n",
      "Func worker, run time: 24.947579622268677\n",
      "Func splitData, run time: 0.166611909866333\n",
      "Experiment 8:\n",
      "Metric: {'Precision': 0.31, 'Recall': 0.51, 'Coverage': 16.89, 'Diversity': 0.8827969355885321, 'Popularity': 1.327572}\n",
      "Func worker, run time: 25.43095898628235\n",
      "Func splitData, run time: 0.16591262817382812\n",
      "Experiment 9:\n",
      "Metric: {'Precision': 0.33, 'Recall': 0.55, 'Coverage': 16.98, 'Diversity': 0.8824916027061752, 'Popularity': 1.323395}\n",
      "Func worker, run time: 25.062614679336548\n",
      "Average Result (M=10, N=10): {'Precision': 0.352, 'Recall': 0.5799999999999998, 'Coverage': 16.952, 'Diversity': 0.8830170186083152, 'Popularity': 1.3244642}\n",
      "Func run, run time: 264.25484585762024\n"
     ]
    }
   ],
   "source": [
    "# 2. TagBasedTFIDF实验\n",
    "M, N = 10, 10\n",
    "exp = Experiment(M, N, rt='TagBasedTFIDF')\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func loadData, run time: 0.6746134757995605\n",
      "Func splitData, run time: 0.21011662483215332\n",
      "Experiment 0:\n",
      "Metric: {'Precision': 0.14, 'Recall': 0.23, 'Coverage': 19.4, 'Diversity': 0.8599380604172997, 'Popularity': 0.786325}\n",
      "Func worker, run time: 30.299565076828003\n",
      "Func splitData, run time: 0.17536473274230957\n",
      "Experiment 1:\n",
      "Metric: {'Precision': 0.16, 'Recall': 0.27, 'Coverage': 19.36, 'Diversity': 0.8618208608790385, 'Popularity': 0.785819}\n",
      "Func worker, run time: 30.37726640701294\n",
      "Func splitData, run time: 0.1649799346923828\n",
      "Experiment 2:\n",
      "Metric: {'Precision': 0.18, 'Recall': 0.3, 'Coverage': 19.48, 'Diversity': 0.8613625413882212, 'Popularity': 0.787078}\n",
      "Func worker, run time: 30.84911561012268\n",
      "Func splitData, run time: 0.1681976318359375\n",
      "Experiment 3:\n",
      "Metric: {'Precision': 0.15, 'Recall': 0.24, 'Coverage': 19.32, 'Diversity': 0.8633666273569298, 'Popularity': 0.78599}\n",
      "Func worker, run time: 31.04114580154419\n",
      "Func splitData, run time: 0.1666414737701416\n",
      "Experiment 4:\n",
      "Metric: {'Precision': 0.21, 'Recall': 0.34, 'Coverage': 19.38, 'Diversity': 0.8611820286885395, 'Popularity': 0.786397}\n",
      "Func worker, run time: 30.380786657333374\n",
      "Func splitData, run time: 0.1676163673400879\n",
      "Experiment 5:\n",
      "Metric: {'Precision': 0.16, 'Recall': 0.27, 'Coverage': 19.36, 'Diversity': 0.860780904040672, 'Popularity': 0.786876}\n",
      "Func worker, run time: 32.267828702926636\n",
      "Func splitData, run time: 0.19611310958862305\n",
      "Experiment 6:\n",
      "Metric: {'Precision': 0.16, 'Recall': 0.26, 'Coverage': 19.43, 'Diversity': 0.8622032886005742, 'Popularity': 0.784251}\n",
      "Func worker, run time: 33.255096673965454\n",
      "Func splitData, run time: 0.16867399215698242\n",
      "Experiment 7:\n",
      "Metric: {'Precision': 0.16, 'Recall': 0.26, 'Coverage': 19.57, 'Diversity': 0.8625679865612409, 'Popularity': 0.785627}\n",
      "Func worker, run time: 31.571264505386353\n",
      "Func splitData, run time: 0.238814115524292\n",
      "Experiment 8:\n",
      "Metric: {'Precision': 0.15, 'Recall': 0.24, 'Coverage': 19.41, 'Diversity': 0.8605516786945571, 'Popularity': 0.784418}\n",
      "Func worker, run time: 33.617796897888184\n",
      "Func splitData, run time: 0.16915583610534668\n",
      "Experiment 9:\n",
      "Metric: {'Precision': 0.16, 'Recall': 0.26, 'Coverage': 19.41, 'Diversity': 0.8584893616206543, 'Popularity': 0.785889}\n",
      "Func worker, run time: 31.26989984512329\n",
      "Average Result (M=10, N=10): {'Precision': 0.16299999999999998, 'Recall': 0.267, 'Coverage': 19.412, 'Diversity': 0.8612263338247728, 'Popularity': 0.785867}\n",
      "Func run, run time: 317.47725200653076\n"
     ]
    }
   ],
   "source": [
    "# 3. TagBasedTFIDF++实验\n",
    "M, N = 10, 10\n",
    "exp = Experiment(M, N, rt='TagBasedTFIDF_Improved')\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func loadData, run time: 0.7549943923950195\n",
      "Func splitData, run time: 0.11275315284729004\n",
      "Experiment 0:\n",
      "Metric: {'Precision': 0.33, 'Recall': 0.54, 'Coverage': 3.36, 'Diversity': 0.7884883018040946, 'Popularity': 2.338678}\n",
      "Func worker, run time: 25.16828966140747\n",
      "Func splitData, run time: 0.18948864936828613\n",
      "Experiment 1:\n",
      "Metric: {'Precision': 0.37, 'Recall': 0.61, 'Coverage': 3.46, 'Diversity': 0.7884401302254415, 'Popularity': 2.323418}\n",
      "Func worker, run time: 26.124404430389404\n",
      "Func splitData, run time: 0.1703495979309082\n",
      "Experiment 2:\n",
      "Metric: {'Precision': 0.36, 'Recall': 0.6, 'Coverage': 3.46, 'Diversity': 0.7921329260858774, 'Popularity': 2.323827}\n",
      "Func worker, run time: 25.99972367286682\n",
      "Func splitData, run time: 0.17077875137329102\n",
      "Experiment 3:\n",
      "Metric: {'Precision': 0.29, 'Recall': 0.47, 'Coverage': 3.39, 'Diversity': 0.7976252561889152, 'Popularity': 2.361773}\n",
      "Func worker, run time: 25.42745089530945\n",
      "Func splitData, run time: 0.17133283615112305\n",
      "Experiment 4:\n",
      "Metric: {'Precision': 0.37, 'Recall': 0.62, 'Coverage': 3.4, 'Diversity': 0.790916525148066, 'Popularity': 2.33289}\n",
      "Func worker, run time: 25.87478470802307\n",
      "Func splitData, run time: 0.1791987419128418\n",
      "Experiment 5:\n",
      "Metric: {'Precision': 0.34, 'Recall': 0.57, 'Coverage': 3.33, 'Diversity': 0.788429877019891, 'Popularity': 2.343771}\n",
      "Func worker, run time: 26.828704118728638\n",
      "Func splitData, run time: 0.23647522926330566\n",
      "Experiment 6:\n",
      "Metric: {'Precision': 0.37, 'Recall': 0.6, 'Coverage': 3.53, 'Diversity': 0.7933746741699387, 'Popularity': 2.302499}\n",
      "Func worker, run time: 27.694408893585205\n",
      "Func splitData, run time: 0.17095470428466797\n",
      "Experiment 7:\n",
      "Metric: {'Precision': 0.33, 'Recall': 0.55, 'Coverage': 3.45, 'Diversity': 0.790011167182502, 'Popularity': 2.359592}\n",
      "Func worker, run time: 26.928112506866455\n",
      "Func splitData, run time: 0.17833614349365234\n",
      "Experiment 8:\n",
      "Metric: {'Precision': 0.33, 'Recall': 0.53, 'Coverage': 3.42, 'Diversity': 0.7876792189772115, 'Popularity': 2.340065}\n",
      "Func worker, run time: 26.510884523391724\n",
      "Func splitData, run time: 0.17745423316955566\n",
      "Experiment 9:\n",
      "Metric: {'Precision': 0.35, 'Recall': 0.58, 'Coverage': 3.35, 'Diversity': 0.7874927049516082, 'Popularity': 2.337212}\n",
      "Func worker, run time: 26.243794441223145\n",
      "Average Result (M=10, N=10): {'Precision': 0.34400000000000003, 'Recall': 0.567, 'Coverage': 3.415, 'Diversity': 0.7904590781753547, 'Popularity': 2.3363725}\n",
      "Func run, run time: 265.36006808280945\n"
     ]
    }
   ],
   "source": [
    "# 4. TagExtend实验\n",
    "M, N = 10, 10\n",
    "exp = Experiment(M, N, rt='ExtendTagBased')\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四. 实验结果 性能为何这么差???\n",
    "算法的实现上应该没啥问题啊，难道是数据集太小？\n",
    "\n",
    "1. SimpleTagBased实验\n",
    "\n",
    "    Running time: 404.8816478252411\n",
    "    \n",
    "    Average Result (M=10, N=10): {'Precision': 0.33699999999999997, 'Recall': 0.5529999999999999, 'Coverage': 3.3609999999999998, 'Diversity': 0.7913794301955859, 'Popularity': 2.3396786}\n",
    "     \n",
    "2. TagBasedTFIDF实验\n",
    "    \n",
    "    Running time: 443.55260705947876\n",
    "    \n",
    "    Average Result (M=10, N=10): {'Precision': 0.352, 'Recall': 0.5799999999999998, 'Coverage': 16.952, 'Diversity': 0.8829974324199723, 'Popularity': 1.3243864}\n",
    "     \n",
    "3. TagBasedTFIDF_Improved实验\n",
    "    \n",
    "    Running time: 551.4401750564575\n",
    "    \n",
    "    Average Result (M=10, N=10): {'Precision': 0.16299999999999998, 'Recall': 0.267, 'Coverage': 19.410999999999998, 'Diversity': 0.8612131974012064, 'Popularity': 0.7858693999999999}\n",
    "\n",
    "4. ExtendTagBased实验\n",
    "\n",
    "    Running time: 430.87147402763367\n",
    "    \n",
    "    Average Result (M=10, N=10): {'Precision': 0.34400000000000003, 'Recall': 0.5660000000000001, 'Coverage': 3.4150000000000005, 'Diversity': 0.7904256291985878, 'Popularity': 2.336292}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附：运行日志（请双击看）\n",
    "\n",
    "1. SimpleTagBased实验\n",
    "Func loadData, run time: 1.6280088424682617\n",
    "Func splitData, run time: 0.30851316452026367\n",
    "Experiment 0:\n",
    "Metric: {'Precision': 0.33, 'Recall': 0.54, 'Coverage': 3.33, 'Diversity': 0.7889366782206686, 'Popularity': 2.341392}\n",
    "Func worker, run time: 37.870625019073486\n",
    "Func splitData, run time: 0.3097972869873047\n",
    "Experiment 1:\n",
    "Metric: {'Precision': 0.36, 'Recall': 0.59, 'Coverage': 3.37, 'Diversity': 0.789191306584079, 'Popularity': 2.326798}\n",
    "Func worker, run time: 38.06450700759888\n",
    "Func splitData, run time: 0.32140111923217773\n",
    "Experiment 2:\n",
    "Metric: {'Precision': 0.36, 'Recall': 0.59, 'Coverage': 3.37, 'Diversity': 0.7930642205047819, 'Popularity': 2.327752}\n",
    "Func worker, run time: 43.02850008010864\n",
    "Func splitData, run time: 0.32935285568237305\n",
    "Experiment 3:\n",
    "Metric: {'Precision': 0.29, 'Recall': 0.48, 'Coverage': 3.35, 'Diversity': 0.7980044140029352, 'Popularity': 2.3653}\n",
    "Func worker, run time: 39.16614294052124\n",
    "Func splitData, run time: 0.1974170207977295\n",
    "Experiment 4:\n",
    "Metric: {'Precision': 0.34, 'Recall': 0.56, 'Coverage': 3.33, 'Diversity': 0.7913038648261218, 'Popularity': 2.33633}\n",
    "Func worker, run time: 41.13529896736145\n",
    "Func splitData, run time: 0.19643640518188477\n",
    "Experiment 5:\n",
    "Metric: {'Precision': 0.33, 'Recall': 0.55, 'Coverage': 3.29, 'Diversity': 0.7897780704681152, 'Popularity': 2.346427}\n",
    "Func worker, run time: 38.96295094490051\n",
    "Func splitData, run time: 0.19998574256896973\n",
    "Experiment 6:\n",
    "Metric: {'Precision': 0.35, 'Recall': 0.56, 'Coverage': 3.48, 'Diversity': 0.7947467303677718, 'Popularity': 2.305821}\n",
    "Func worker, run time: 40.37690997123718\n",
    "Func splitData, run time: 0.19191503524780273\n",
    "Experiment 7:\n",
    "Metric: {'Precision': 0.33, 'Recall': 0.55, 'Coverage': 3.39, 'Diversity': 0.7909845940006351, 'Popularity': 2.362614}\n",
    "Func worker, run time: 41.105441093444824\n",
    "Func splitData, run time: 0.1934211254119873\n",
    "Experiment 8:\n",
    "Metric: {'Precision': 0.34, 'Recall': 0.55, 'Coverage': 3.37, 'Diversity': 0.7895494174800041, 'Popularity': 2.343617}\n",
    "Func worker, run time: 39.65980076789856\n",
    "Func splitData, run time: 0.1929779052734375\n",
    "Experiment 9:\n",
    "Metric: {'Precision': 0.34, 'Recall': 0.56, 'Coverage': 3.33, 'Diversity': 0.7882350055007459, 'Popularity': 2.340735}\n",
    "Func worker, run time: 41.376152992248535\n",
    "Average Result (M=10, N=10): {'Precision': 0.33699999999999997, 'Recall': 0.5529999999999999, 'Coverage': 3.3609999999999998, 'Diversity': 0.7913794301955859, 'Popularity': 2.3396786}\n",
    "Func run, run time: 404.8816478252411\n",
    "\n",
    "2. TagBasedTFIDF实验\n",
    "Func loadData, run time: 1.6277968883514404\n",
    "Func splitData, run time: 0.27590298652648926\n",
    "Experiment 0:\n",
    "Metric: {'Precision': 0.38, 'Recall': 0.62, 'Coverage': 16.84, 'Diversity': 0.8817864660115259, 'Popularity': 1.324191}\n",
    "Func worker, run time: 46.15612602233887\n",
    "Func splitData, run time: 0.31597304344177246\n",
    "Experiment 1:\n",
    "Metric: {'Precision': 0.39, 'Recall': 0.64, 'Coverage': 16.95, 'Diversity': 0.8826858063646551, 'Popularity': 1.316902}\n",
    "Func worker, run time: 43.69584107398987\n",
    "Func splitData, run time: 0.24825787544250488\n",
    "Experiment 2:\n",
    "Metric: {'Precision': 0.35, 'Recall': 0.58, 'Coverage': 16.95, 'Diversity': 0.8810856212597441, 'Popularity': 1.32838}\n",
    "Func worker, run time: 43.3360550403595\n",
    "Func splitData, run time: 0.26052021980285645\n",
    "Experiment 3:\n",
    "Metric: {'Precision': 0.3, 'Recall': 0.5, 'Coverage': 16.98, 'Diversity': 0.8852701028022301, 'Popularity': 1.324043}\n",
    "Func worker, run time: 43.02037310600281\n",
    "Func splitData, run time: 0.26059913635253906\n",
    "Experiment 4:\n",
    "Metric: {'Precision': 0.39, 'Recall': 0.65, 'Coverage': 16.93, 'Diversity': 0.8839700173444075, 'Popularity': 1.318708}\n",
    "Func worker, run time: 44.03740382194519\n",
    "Func splitData, run time: 0.25109100341796875\n",
    "Experiment 5:\n",
    "Metric: {'Precision': 0.36, 'Recall': 0.59, 'Coverage': 16.86, 'Diversity': 0.8819926728499792, 'Popularity': 1.332067}\n",
    "Func worker, run time: 43.196900844573975\n",
    "Func splitData, run time: 0.26158785820007324\n",
    "Experiment 6:\n",
    "Metric: {'Precision': 0.36, 'Recall': 0.58, 'Coverage': 17.06, 'Diversity': 0.8857461664078716, 'Popularity': 1.317056}\n",
    "Func worker, run time: 43.58964991569519\n",
    "Func splitData, run time: 0.26162195205688477\n",
    "Experiment 7:\n",
    "Metric: {'Precision': 0.35, 'Recall': 0.58, 'Coverage': 17.08, 'Diversity': 0.8821745724171214, 'Popularity': 1.331707}\n",
    "Func worker, run time: 43.189525842666626\n",
    "Func splitData, run time: 0.23992609977722168\n",
    "Experiment 8:\n",
    "Metric: {'Precision': 0.31, 'Recall': 0.51, 'Coverage': 16.89, 'Diversity': 0.8827909053583793, 'Popularity': 1.327498}\n",
    "Func worker, run time: 45.02846622467041\n",
    "Func splitData, run time: 0.25911593437194824\n",
    "Experiment 9:\n",
    "Metric: {'Precision': 0.33, 'Recall': 0.55, 'Coverage': 16.98, 'Diversity': 0.8824719933838076, 'Popularity': 1.323312}\n",
    "Func worker, run time: 43.965688705444336\n",
    "Average Result (M=10, N=10): {'Precision': 0.352, 'Recall': 0.5799999999999998, 'Coverage': 16.952, 'Diversity': 0.8829974324199723, 'Popularity': 1.3243864}\n",
    "Func run, run time: 443.55260705947876\n",
    "\n",
    "3. TagBasedTFIDF++实验\n",
    "Func loadData, run time: 1.2623248100280762\n",
    "Func splitData, run time: 0.2863779067993164\n",
    "Experiment 0:\n",
    "Metric: {'Precision': 0.14, 'Recall': 0.23, 'Coverage': 19.4, 'Diversity': 0.859877838307336, 'Popularity': 0.786183}\n",
    "Func worker, run time: 54.93890690803528\n",
    "Func splitData, run time: 0.2523970603942871\n",
    "Experiment 1:\n",
    "Metric: {'Precision': 0.16, 'Recall': 0.27, 'Coverage': 19.36, 'Diversity': 0.8617994094261496, 'Popularity': 0.785819}\n",
    "Func worker, run time: 54.65705108642578\n",
    "Func splitData, run time: 0.26293516159057617\n",
    "Experiment 2:\n",
    "Metric: {'Precision': 0.18, 'Recall': 0.3, 'Coverage': 19.48, 'Diversity': 0.861349178757724, 'Popularity': 0.787125}\n",
    "Func worker, run time: 54.77145004272461\n",
    "Func splitData, run time: 0.2572140693664551\n",
    "Experiment 3:\n",
    "Metric: {'Precision': 0.15, 'Recall': 0.24, 'Coverage': 19.32, 'Diversity': 0.8633524800153738, 'Popularity': 0.78599}\n",
    "Func worker, run time: 54.72025799751282\n",
    "Func splitData, run time: 0.2647433280944824\n",
    "Experiment 4:\n",
    "Metric: {'Precision': 0.21, 'Recall': 0.34, 'Coverage': 19.38, 'Diversity': 0.8611766478285409, 'Popularity': 0.786397}\n",
    "Func worker, run time: 54.61092400550842\n",
    "Func splitData, run time: 0.2570078372955322\n",
    "Experiment 5:\n",
    "Metric: {'Precision': 0.16, 'Recall': 0.27, 'Coverage': 19.36, 'Diversity': 0.8607577942073997, 'Popularity': 0.786923}\n",
    "Func worker, run time: 54.64287829399109\n",
    "Func splitData, run time: 0.25312089920043945\n",
    "Experiment 6:\n",
    "Metric: {'Precision': 0.16, 'Recall': 0.26, 'Coverage': 19.43, 'Diversity': 0.8622121035638752, 'Popularity': 0.784275}\n",
    "Func worker, run time: 54.19543790817261\n",
    "Func splitData, run time: 0.25305795669555664\n",
    "Experiment 7:\n",
    "Metric: {'Precision': 0.16, 'Recall': 0.26, 'Coverage': 19.57, 'Diversity': 0.8625286276619254, 'Popularity': 0.785651}\n",
    "Func worker, run time: 54.9225959777832\n",
    "Func splitData, run time: 0.24744105339050293\n",
    "Experiment 8:\n",
    "Metric: {'Precision': 0.15, 'Recall': 0.24, 'Coverage': 19.41, 'Diversity': 0.8605756591696193, 'Popularity': 0.784442}\n",
    "Func worker, run time: 56.0502827167511\n",
    "Func splitData, run time: 0.25081896781921387\n",
    "Experiment 9:\n",
    "Metric: {'Precision': 0.16, 'Recall': 0.26, 'Coverage': 19.4, 'Diversity': 0.8585022350741194, 'Popularity': 0.785889}\n",
    "Func worker, run time: 54.0096640586853\n",
    "Average Result (M=10, N=10): {'Precision': 0.16299999999999998, 'Recall': 0.267, 'Coverage': 19.410999999999998, 'Diversity': 0.8612131974012064, 'Popularity': 0.7858693999999999}\n",
    "Func run, run time: 551.4401750564575\n",
    "\n",
    "4. ExtendTagBased实验\n",
    "Func loadData, run time: 1.888315200805664\n",
    "Func splitData, run time: 0.18341422080993652\n",
    "Experiment 0:\n",
    "Metric: {'Precision': 0.33, 'Recall': 0.54, 'Coverage': 3.37, 'Diversity': 0.7882770482685956, 'Popularity': 2.338341}\n",
    "Func worker, run time: 45.58587598800659\n",
    "Func splitData, run time: 0.342771053314209\n",
    "Experiment 1:\n",
    "Metric: {'Precision': 0.37, 'Recall': 0.61, 'Coverage': 3.45, 'Diversity': 0.7884184200805971, 'Popularity': 2.323208}\n",
    "Func worker, run time: 43.79095387458801\n",
    "Func splitData, run time: 0.18767595291137695\n",
    "Experiment 2:\n",
    "Metric: {'Precision': 0.36, 'Recall': 0.6, 'Coverage': 3.47, 'Diversity': 0.7920836566910633, 'Popularity': 2.323179}\n",
    "Func worker, run time: 45.01177382469177\n",
    "Func splitData, run time: 0.3437650203704834\n",
    "Experiment 3:\n",
    "Metric: {'Precision': 0.29, 'Recall': 0.47, 'Coverage': 3.39, 'Diversity': 0.7975400160363582, 'Popularity': 2.361645}\n",
    "Func worker, run time: 40.95514512062073\n",
    "Func splitData, run time: 0.3429849147796631\n",
    "Experiment 4:\n",
    "Metric: {'Precision': 0.37, 'Recall': 0.62, 'Coverage': 3.4, 'Diversity': 0.7909206637230392, 'Popularity': 2.333121}\n",
    "Func worker, run time: 41.210543155670166\n",
    "Func splitData, run time: 0.32721614837646484\n",
    "Experiment 5:\n",
    "Metric: {'Precision': 0.34, 'Recall': 0.56, 'Coverage': 3.33, 'Diversity': 0.788432348430914, 'Popularity': 2.344057}\n",
    "Func worker, run time: 41.1824209690094\n",
    "Func splitData, run time: 0.19087624549865723\n",
    "Experiment 6:\n",
    "Metric: {'Precision': 0.37, 'Recall': 0.6, 'Coverage': 3.52, 'Diversity': 0.7933734279462265, 'Popularity': 2.302654}\n",
    "Func worker, run time: 44.1220920085907\n",
    "Func splitData, run time: 0.3399050235748291\n",
    "Experiment 7:\n",
    "Metric: {'Precision': 0.33, 'Recall': 0.55, 'Coverage': 3.45, 'Diversity': 0.7899962076862624, 'Popularity': 2.359363}\n",
    "Func worker, run time: 41.13612079620361\n",
    "Func splitData, run time: 0.3469550609588623\n",
    "Experiment 8:\n",
    "Metric: {'Precision': 0.33, 'Recall': 0.53, 'Coverage': 3.41, 'Diversity': 0.7877338070843662, 'Popularity': 2.340181}\n",
    "Func worker, run time: 41.45753598213196\n",
    "Func splitData, run time: 0.34490013122558594\n",
    "Experiment 9:\n",
    "Metric: {'Precision': 0.35, 'Recall': 0.58, 'Coverage': 3.36, 'Diversity': 0.7874806960384569, 'Popularity': 2.337171}\n",
    "Func worker, run time: 41.51561903953552\n",
    "Average Result (M=10, N=10): {'Precision': 0.34400000000000003, 'Recall': 0.5660000000000001, 'Coverage': 3.4150000000000005, 'Diversity': 0.7904256291985878, 'Popularity': 2.336292}\n",
    "Func run, run time: 430.87147402763367"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
